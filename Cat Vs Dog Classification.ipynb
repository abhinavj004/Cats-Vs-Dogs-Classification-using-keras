{
  "cells": [
    {
      "metadata": {
        "_uuid": "b68f6948e99b809ac2a57272cdf5efbc57b76e0f"
      },
      "cell_type": "markdown",
      "source": "# Building a strong image classification model using keras"
    },
    {
      "metadata": {
        "_uuid": "276efe6f672011a8171cb2f7ecbdf871dbc96304"
      },
      "cell_type": "markdown",
      "source": "\n**** CONTENTS::****\n\n**** 1 ) Importing Various Modules****\n\n ****2 ) Prepare the Data****\n \n ****3 ) Modelling****\n \n ****4 ) Evaluating the Model Performance****\n \n ****5) Making Predictions on the Test Set****\n \n**** 6) Saving Submissions onto a CSV  ****\n"
    },
    {
      "metadata": {
        "_uuid": "63aacd020911a13c93d8851b5b584a70482565ff"
      },
      "cell_type": "markdown",
      "source": "## 1)Importing libraries and constants for Preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6b05417f8c123893b6af5eabd04f404b4c23d436"
      },
      "cell_type": "code",
      "source": "import cv2                 # working with, mainly resizing, images\nimport numpy as np         # dealing with arrays\nimport os                  # dealing with directories\nfrom random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n\ntrain_dir = '../input/train'\ntest_dir = '../input/test'",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e1a361765c5d25fb25a3e8b17886c3340f94004"
      },
      "cell_type": "markdown",
      "source": "## 2)Preparing the data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf2feb128a9a38cf2f31e982996fcd1194a29736"
      },
      "cell_type": "markdown",
      "source": "## 2.1)conversion to one-hot array for cat it is [1,0] and for dog it is [0,1]"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fdbb40f595170be6ad74e572b805716b64238a9d"
      },
      "cell_type": "code",
      "source": "def get_label(img):\n    label = img.split('.')[0]\n    if label == 'cat': \n        return [1,0]\n    elif label == 'dog': \n        return [0,1]",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4008882f89d91b0018ca582b700cde0064b33cbf"
      },
      "cell_type": "markdown",
      "source": "## 2.2)Building  another function to fully process the training images and their labels into arrays:-"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b46cf58d19996037dd0dbf036eb531a698ca0038"
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm      # a nice pretty percentage bar for tasks.\n\ndef making_train_data():\n    training_data = []\n    \n    for img in tqdm(os.listdir(train_dir)):\n        label = get_label(img)\n        path = os.path.join(train_dir,img)\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (50,50))\n        training_data.append([np.array(img),np.array(label)])\n        \n    shuffle(training_data)\n    np.save('train_data.npy', training_data)\n    return training_data",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "18915db0ccb5cf67184c6c397c0098b3afce8176"
      },
      "cell_type": "code",
      "source": "def making_test_data():\n    testing_data = []\n    \n    for img in tqdm(os.listdir(test_dir)):\n        path = os.path.join(test_dir , img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path , cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img , (50,50))\n        testing_data.append([np.array(img), img_num])\n        \n    shuffle(testing_data)\n    np.save('test_data.npy', testing_data)\n    return testing_data",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8b65aabe5028f50d125136a52c969515be09f634"
      },
      "cell_type": "code",
      "source": "train_data = making_train_data()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 25000/25000 [01:39<00:00, 250.21it/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "1f708032fa5750766b4f44a008c9a5d175975a85"
      },
      "cell_type": "markdown",
      "source": "## 2.3)Split the train_data into train(having 20,000 images) and test(having 5,000 images) "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "04ff1544d429f03c2dfc3d08305986271ee09bc4"
      },
      "cell_type": "code",
      "source": "train = train_data[0:20000]\ntest = train_data[20000:25000]",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c3d841927f380f1e2ab0013f23b057ecb89dfbab"
      },
      "cell_type": "code",
      "source": "X = np.array([i[0] for i in train]).reshape(-1,1,50,50)\nY = [i[1] for i in train]\n\ntest_x = np.array([i[0] for i in test]).reshape(-1,1,50,50)\ntest_y = [i[1] for i in test]",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c7ef4c2965b05e13dca956cc384e8f3cb934a9cf"
      },
      "cell_type": "markdown",
      "source": "## 2.4)Data Augmentation to prevent Overfitting"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eaf17e547b351a7c8995662787fc3daf0afa95a5",
        "_kg_hide-input": false
      },
      "cell_type": "code",
      "source": "from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False,  \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=10,  \n        zoom_range = 0.0,  \n        width_shift_range=0.1,  \n        height_shift_range=0.1,  \n        horizontal_flip=False, \n        vertical_flip=False)  \n\ndatagen.fit(X)",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Using TensorFlow backend.\n/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image.py:1358: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (20000, 1, 50, 50) (50 channels).\n  ' channels).')\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d4239c829f5c6cfe5fa6a170b9d872ff394766f4"
      },
      "cell_type": "code",
      "source": "Y = np.asarray(Y)\nY.reshape(len(Y) , 2)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "array([[1, 0],\n       [0, 1],\n       [1, 0],\n       ...,\n       [1, 0],\n       [1, 0],\n       [1, 0]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "40b58317702fec39ceaa84a85d96942a6875503e"
      },
      "cell_type": "code",
      "source": "test_y = np.asarray(test_y)\ntest_y.reshape(len(test_y) , 2)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "array([[1, 0],\n       [0, 1],\n       [1, 0],\n       ...,\n       [1, 0],\n       [0, 1],\n       [0, 1]])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d91a18a73518eea667f7d64a7160e15bdd9592e2"
      },
      "cell_type": "code",
      "source": "test_x = test_x.reshape(-1, 1, 50, 50)",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c567cef43e9d6a4ed812b3822304b9efdabf49b2"
      },
      "cell_type": "code",
      "source": "test_x = test_x / 255\nX = X / 255",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f15356bae02f6cf471f02a97c8978ecaf2d28fad"
      },
      "cell_type": "markdown",
      "source": "****We will be using the Sequential model from Keras to form the Neural Network. Sequential Model is used to construct simple models with linear stack of layers.****\n\n****More info on Sequential model and Keras in general at https://keras.io/getting-started/sequential-model-guide/ and https://github.com/keras-team/keras****"
    },
    {
      "metadata": {
        "_uuid": "19b024c353746d946e8ade785748b5cfd4492876"
      },
      "cell_type": "markdown",
      "source": "## ## 3)Modelling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ed99a41cb74507cb7771bd4051f9217bae0091dd"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense , Activation\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.layers import Convolution2D\nfrom keras.layers import Conv2D , BatchNormalization\nfrom keras.layers import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "82100e50ad688f2672b32bf558c74f62ad1bda4d"
      },
      "cell_type": "markdown",
      "source": "## 3.1)Building the ConvNet Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f3d125c14972757fba99093af2384c13345d46b8"
      },
      "cell_type": "code",
      "source": "# Initialising the CNN\nclassifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Convolution2D(32, 3, 3, input_shape = (1,50,50), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer\nclassifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n\n\n# Adding a third convolutional layer\nclassifier.add(Convolution2D(64, 3, 3, activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n\n\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full connection\nclassifier.add(Dense(output_dim = 64, activation = 'relu'))\nclassifier.add(Dropout(0.4))\nclassifier.add(Dense(output_dim = 2, activation = 'sigmoid'))\n\n",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(1, 50, 50..., activation=\"relu\")`\n  \"\"\"\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n  # This is added back by InteractiveShellApp.init_path()\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=64)`\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=2)`\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "33853e4625de26c1e7576c3c49f3b4b6d8e0ece4"
      },
      "cell_type": "markdown",
      "source": "## 3.2)Compiling the Keras Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "648eef187a41975a98a0e491eeeee50475988364"
      },
      "cell_type": "code",
      "source": "# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e98879fef7dbc06ae80625cc99bb8ca46a5179c9"
      },
      "cell_type": "markdown",
      "source": "## 3.3)Summary of the Model"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "34b38918b670c8c194467a90d8269e69dc3bdb60"
      },
      "cell_type": "code",
      "source": "classifier.summary()",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 32, 48, 48)        320       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 32, 24, 24)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 32, 22, 22)        9248      \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 32, 11, 11)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 64, 9, 9)          18496     \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 64, 4, 4)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 64)                65600     \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 64)                0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 130       \n=================================================================\nTotal params: 93,794\nTrainable params: 93,794\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "5f97d29998adf5d5de9d7de1a2dbc18457efc9b3"
      },
      "cell_type": "markdown",
      "source": "## 3.4)Fitting on the Training set and making predcitons on the Validation set"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b1a42acd4a50f25c4ed9a5f509582b684c12028f"
      },
      "cell_type": "code",
      "source": "batch_size = 128\nepochs = 20\n\nclassifier.compile(loss='binary_crossentropy', optimizer='adam' , metrics=['accuracy'])\nsteps_per_epoch = len(train_data) // batch_size\nvalidation_steps = len((test_x, test_y)) // batch_size",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b9079c6a2428c393e89389b28e399c7fc80d21b2"
      },
      "cell_type": "code",
      "source": "history = classifier.fit_generator(datagen.flow(X, Y, batch_size=batch_size),\n                    steps_per_epoch=X.shape[0] // batch_size,\n                    validation_data=(test_x, test_y),\n                    epochs = epochs, verbose = 2)",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/keras_preprocessing/image.py:1643: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (20000, 1, 50, 50) (50 channels).\n  str(self.x.shape[channels_axis]) + ' channels).')\n",
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": "Epoch 1/20\n - 27s - loss: 0.6778 - acc: 0.5572 - val_loss: 0.6393 - val_acc: 0.6317\nEpoch 2/20\n - 27s - loss: 0.6291 - acc: 0.6496 - val_loss: 0.6095 - val_acc: 0.6565\nEpoch 3/20\n - 27s - loss: 0.5749 - acc: 0.7027 - val_loss: 0.5542 - val_acc: 0.7103\nEpoch 4/20\n - 27s - loss: 0.5338 - acc: 0.7361 - val_loss: 0.5229 - val_acc: 0.7452\nEpoch 5/20\n - 27s - loss: 0.4942 - acc: 0.7648 - val_loss: 0.4730 - val_acc: 0.7718\nEpoch 6/20\n - 27s - loss: 0.4758 - acc: 0.7777 - val_loss: 0.4677 - val_acc: 0.7776\nEpoch 7/20\n - 27s - loss: 0.4613 - acc: 0.7844 - val_loss: 0.4453 - val_acc: 0.7904\nEpoch 8/20\n - 27s - loss: 0.4471 - acc: 0.7968 - val_loss: 0.4457 - val_acc: 0.7873\nEpoch 9/20\n - 27s - loss: 0.4285 - acc: 0.8049 - val_loss: 0.4267 - val_acc: 0.8009\nEpoch 10/20\n - 27s - loss: 0.4134 - acc: 0.8092 - val_loss: 0.4123 - val_acc: 0.8125\nEpoch 11/20\n - 26s - loss: 0.3974 - acc: 0.8211 - val_loss: 0.4112 - val_acc: 0.8102\nEpoch 12/20\n - 27s - loss: 0.3963 - acc: 0.8194 - val_loss: 0.4062 - val_acc: 0.8119\nEpoch 13/20\n - 27s - loss: 0.3814 - acc: 0.8288 - val_loss: 0.4011 - val_acc: 0.8168\nEpoch 14/20\n - 26s - loss: 0.3704 - acc: 0.8359 - val_loss: 0.3814 - val_acc: 0.8302\nEpoch 15/20\n - 26s - loss: 0.3641 - acc: 0.8387 - val_loss: 0.3936 - val_acc: 0.8245\nEpoch 16/20\n - 26s - loss: 0.3475 - acc: 0.8479 - val_loss: 0.3723 - val_acc: 0.8320\nEpoch 17/20\n - 27s - loss: 0.3384 - acc: 0.8514 - val_loss: 0.4151 - val_acc: 0.8161\nEpoch 18/20\n - 26s - loss: 0.3378 - acc: 0.8526 - val_loss: 0.3744 - val_acc: 0.8324\nEpoch 19/20\n - 26s - loss: 0.3279 - acc: 0.8550 - val_loss: 0.3725 - val_acc: 0.8307\nEpoch 20/20\n - 27s - loss: 0.3176 - acc: 0.8625 - val_loss: 0.3689 - val_acc: 0.8385\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0ef513b6683f8eb7c0d246d840058ed436ba2c3"
      },
      "cell_type": "code",
      "source": "test_data = making_test_data()",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 12500/12500 [00:47<00:00, 261.54it/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7ffcfa8c53022d59f2fae5136c9ca3a579a9b5dd"
      },
      "cell_type": "code",
      "source": "score = classifier.evaluate(test_x, test_y, verbose=0)\nprint('valid loss:', score[0])\nprint('valid accuracy:', score[1])",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "valid loss: 0.3688554729938507\nvalid accuracy: 0.8385\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9231debfda99bda01b19ea58f8c9dc0eced8232f"
      },
      "cell_type": "code",
      "source": "with open('submission_file.csv','w') as f:\n    f.write('id,label\\n')\n            \nwith open('submission_file.csv','a') as f:\n    for data in tqdm(test_data):\n        img_num = data[1]\n        img_data = data[0]\n        orig = img_data\n        data = img_data.reshape(1,1,50,50)\n        model_out = classifier.predict([data])[0]\n        f.write('{},{}\\n'.format(img_num,model_out[1]))",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 12500/12500 [00:18<00:00, 677.94it/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bab1b3e04302fa0de586b9bc91a58539bc1b2dea"
      },
      "cell_type": "code",
      "source": "import pandas as pd\naa = pd.read_csv('submission_file.csv')\naa\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fe7ebcf785629eb9dea3bc2303d55a4d2eb70bac"
      },
      "cell_type": "code",
      "source": "from subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nprint(check_output([\"ls\", \"../working\"]).decode(\"utf8\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "873c2485b650ddcbaeaea69161d54999164d8bad"
      },
      "cell_type": "code",
      "source": "data_to_submit = pd.DataFrame({\n    'id':aa['id'],\n    'label':aa['label']\n})\ndata_to_submit.to_csv('submission_file.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cf1367fea4f71b8deb9b844d681b3d344d11e9e4"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}